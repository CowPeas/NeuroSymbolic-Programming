{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y = keras.utils.to_categorical(y, num_classes=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the neural network architecture with both dense and symbolic reasoning layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "inputs = keras.Input(shape=(4,))\n",
    "\n",
    "# Dense layers\n",
    "x = layers.Dense(8, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "\n",
    "# Symbolic reasoning layers\n",
    "logical = layers.Lambda(lambda x: tf.cast(tf.math.greater(x, 0), tf.float32))(x)\n",
    "and_op = layers.Lambda(lambda x: tf.reduce_prod(x, axis=1, keepdims=True))(logical)\n",
    "or_op = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True))(logical)\n",
    "not_op = layers.Lambda(lambda x: 1 - x)(logical)\n",
    "\n",
    "# Concatenate dense and symbolic layers\n",
    "x = layers.Concatenate()([x, and_op, or_op, not_op])\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y, batch_size=8, epochs=100, validation_split=0.2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
